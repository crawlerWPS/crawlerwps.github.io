
<!DOCTYPE html>
<html lang="zh-cn" class="loading">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>沐神的课 - crawler的小屋</title>
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate" />
    <meta name="keywords" content="Fechin,"> 
    <meta name="description" content="BERT链接
名字来源Bidirectional Encoder Representations from Transformers
模型架构In this work, we denote the ,"> 
    <meta name="author" content="crawler"> 
    <link rel="alternative" href="atom.xml" title="crawler的小屋" type="application/atom+xml"> 
    <link rel="icon" href="/img/favicon.png"> 
    
    
    
    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:title" content="沐神的课 - crawler的小屋"/>
    <meta name="twitter:description" content="BERT链接
名字来源Bidirectional Encoder Representations from Transformers
模型架构In this work, we denote the ,"/>
    
    
    
    
    <meta property="og:site_name" content="crawler的小屋"/>
    <meta property="og:type" content="object"/>
    <meta property="og:title" content="沐神的课 - crawler的小屋"/>
    <meta property="og:description" content="BERT链接
名字来源Bidirectional Encoder Representations from Transformers
模型架构In this work, we denote the ,"/>
    
<link rel="stylesheet" href="/css/diaspora.css">

    <script>window.searchDbPath = "/search.xml";</script>
<meta name="generator" content="Hexo 6.1.0"></head>

<body class="loading">
    <span id="config-title" style="display:none">crawler的小屋</span>
    <div id="loader"></div>
    <div id="single">
    <div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <a class="iconfont icon-home image-icon" href="javascript:;" data-url="http://https://crawlerwps.github.io"></a>
    <div title="播放/暂停" class="iconfont icon-play"></div>
    <h3 class="subtitle">沐神的课</h3>
    <div class="social">
        <div>
            <div class="share">
                <a title="获取二维码" class="iconfont icon-scan" href="javascript:;"></a>
            </div>
            <div id="qr"></div>
        </div>
    </div>
    <div class="scrollbar"></div>
</div>

    <div class="section">
        <div class="article">
    <div class='main'>
        <h1 class="title">沐神的课</h1>
        <div class="stuff">
            <span>四月 11, 2023</span>
            
  <ul class="post-tags-list" itemprop="keywords"><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/nlp/" rel="tag">nlp</a></li></ul>


        </div>
        <div class="content markdown">
            <h1 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h1><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1PL411M7eQ/?share_source=copy_web&vd_source=ffe86b75aa4ca0fac9216ac70edace19">链接</a></p>
<h2 id="名字来源"><a href="#名字来源" class="headerlink" title="名字来源"></a>名字来源</h2><p>Bidirectional Encoder Representations from Transformers</p>
<h2 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h2><p>In this work, we denote the number of layers (i.e., Transformer blocks) as <strong>L</strong>, the hidden size as <strong>H</strong>, and the number of self-attention heads as <strong>A</strong>.<br>We primarily report results on two model sizes:<br><strong>BERTBASE</strong> (L&#x3D;12, H&#x3D;768, A&#x3D;12, Total Parameters&#x3D;110M ) and<br><strong>BERTLARGE</strong> (L&#x3D;24, H&#x3D;1024, A&#x3D;16, Total Parameters&#x3D;340M)<br><img src="https://cdn.jsdelivr.net/gh/crawlerWPS/blogImage@main/img/202304091714574.png" alt="image.png"><br>每一个输入的词元变成三个标注：<br>1.token；词本身的信息<br>2.segment；代表是哪个句子<br>3.position；位置信息</p>
<h3 id="超参数-》可学习参数的大小（回顾Transformer）"><a href="#超参数-》可学习参数的大小（回顾Transformer）" class="headerlink" title="超参数-》可学习参数的大小（回顾Transformer）"></a>超参数-》可学习参数的大小（回顾Transformer）</h3><p>可学习参数主要来自两块：<br>    1.嵌入层；<br>    2.Transformer块；</p>
<h3 id="模型使用的分词"><a href="#模型使用的分词" class="headerlink" title="模型使用的分词"></a>模型使用的分词</h3><h4 id="wordPiece"><a href="#wordPiece" class="headerlink" title="wordPiece"></a>wordPiece</h4><p>根据词出现的频率来做分词</p>
<h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><h2 id="模型架构-1"><a href="#模型架构-1" class="headerlink" title="模型架构"></a>模型架构</h2><p><img src="https://cdn.jsdelivr.net/gh/crawlerWPS/blogImage@main/img/202304101041948.png" alt="image.png"></p>
<h3 id="具体解释"><a href="#具体解释" class="headerlink" title="具体解释"></a>具体解释</h3><h4 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h4><p>可以看到从输入进来之后，输入变成了三份（key, value, query）,实际上就是输入本身复制了三份，因此，这种注意力机制也可以被称作为自注意力机制；<br>然后之所以使用多头注意力机制，是因为单个头注意力机制中需要学习的参数太少，而在多头注意力机制中，引入了W参数作为可学习参数，类似于卷积神经网络中的多通道。</p>
<h4 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h4><p>编码器端的key和value是来自于编码器的最后一层的输出，而query是来自于解码器经过多头注意力机制的输出，这一部分的含义是指寻找解码器的query于key相似的作为下一层的输入。</p>
<h3 id="scaled-dot-product-attention-amp-multi-head-attention"><a href="#scaled-dot-product-attention-amp-multi-head-attention" class="headerlink" title="scaled dot-product attention &amp; multi-head attention"></a>scaled dot-product attention &amp; multi-head attention</h3><p><img src="https://cdn.jsdelivr.net/gh/crawlerWPS/blogImage@main/img/202304101042091.png" alt="image.png"><br>可以看到头的个数为h。把输入映射到低维空间（d-model &#x2F; h）中，然后最后进行拼接成原始的维度（d-model）</p>
<h2 id="dropout-层"><a href="#dropout-层" class="headerlink" title="dropout 层"></a>dropout 层</h2><p>drop &#x3D; 0.1？正则化？</p>
<h1 id="GNN"><a href="#GNN" class="headerlink" title="GNN"></a>GNN</h1><h2 id="静态图神经网络"><a href="#静态图神经网络" class="headerlink" title="静态图神经网络"></a>静态图神经网络</h2><h2 id="动态图神经网络"><a href="#动态图神经网络" class="headerlink" title="动态图神经网络"></a>动态图神经网络</h2>
            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls" data-autoplay="false">
                <source type="audio/mpeg" src="">
            </audio>
            
                <ul id="audio-list" style="display:none">
                    
                        
                            <li title="0" data-url="http://link.hhtjim.com/163/425570952.mp3"></li>
                        
                    
                        
                            <li title="1" data-url="http://link.hhtjim.com/163/425570952.mp3"></li>
                        
                    
                </ul>
            
        </div>
        
    <div id="gitalk-container" class="comment link"
		data-enable="false"
        data-ae="false"
        data-ci=""
        data-cs=""
        data-r=""
        data-o=""
        data-a=""
        data-d="false"
    >查看评论</div>


    </div>
    
        <div class="side">
			<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#BERT"><span class="toc-number">1.</span> <span class="toc-text">BERT</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%8D%E5%AD%97%E6%9D%A5%E6%BA%90"><span class="toc-number">1.1.</span> <span class="toc-text">名字来源</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84"><span class="toc-number">1.2.</span> <span class="toc-text">模型架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0-%E3%80%8B%E5%8F%AF%E5%AD%A6%E4%B9%A0%E5%8F%82%E6%95%B0%E7%9A%84%E5%A4%A7%E5%B0%8F%EF%BC%88%E5%9B%9E%E9%A1%BETransformer%EF%BC%89"><span class="toc-number">1.2.1.</span> <span class="toc-text">超参数-》可学习参数的大小（回顾Transformer）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E7%9A%84%E5%88%86%E8%AF%8D"><span class="toc-number">1.2.2.</span> <span class="toc-text">模型使用的分词</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#wordPiece"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">wordPiece</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Transformer"><span class="toc-number">2.</span> <span class="toc-text">Transformer</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84-1"><span class="toc-number">2.1.</span> <span class="toc-text">模型架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E8%A7%A3%E9%87%8A"><span class="toc-number">2.1.1.</span> <span class="toc-text">具体解释</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Encoder"><span class="toc-number">2.1.1.1.</span> <span class="toc-text">Encoder</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Decoder"><span class="toc-number">2.1.1.2.</span> <span class="toc-text">Decoder</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#scaled-dot-product-attention-amp-multi-head-attention"><span class="toc-number">2.1.2.</span> <span class="toc-text">scaled dot-product attention &amp; multi-head attention</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dropout-%E5%B1%82"><span class="toc-number">2.2.</span> <span class="toc-text">dropout 层</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#GNN"><span class="toc-number">3.</span> <span class="toc-text">GNN</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9D%99%E6%80%81%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">3.1.</span> <span class="toc-text">静态图神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">3.2.</span> <span class="toc-text">动态图神经网络</span></a></li></ol></li></ol>	
        </div>
    
</div>


    </div>
</div>
</body>


<script src="//lib.baomitu.com/jquery/1.8.3/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/typed.js"></script>
<script src="/js/diaspora.js"></script>


<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">


<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>






</html>
